{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e655c2f-a7d2-4104-bd0d-d3edbfe3edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PINNs_Chron import PINN3D, PINN3DSolver\n",
    "\n",
    "# Set data type\n",
    "DTYPE='float32'\n",
    "tf.keras.backend.set_floatx(DTYPE)\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f5d413-ae35-4da8-b56b-eeacbd24e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a7618-ce3a-46c6-a3d7-f6c2c46a1c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', family='Arial', size=SIZE) # controls default text sizes\n",
    "plt.rc('axes', titlesize=SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=10)    # legend fontsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf5924d-e099-46a8-8359-81f1a0adeb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40 Ma model time is 110 Ma geo time\n",
    "uplift = lambda t : np.where(t < 40, .6, .05)\n",
    "tf_uplift = lambda t: tf.where(t < 40, .6, .05)\n",
    "tf_uplift_inv = lambda t, u0, u1, t1: tf.where(t < t1, u0, u1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c15ad-c278-44ee-882a-80b63df28859",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_ar = np.loadtxt('dabie_utm_km.xyz', dtype=DTYPE)\n",
    "topo_x, topo_x_pos = np.unique(topo_ar[:, 0], return_inverse=True)\n",
    "topo_y, topo_y_pos = np.unique(topo_ar[:, 1], return_inverse=True)\n",
    "topo_pivot = np.zeros((len(topo_x), len(topo_y)), dtype=DTYPE)\n",
    "topo_pivot[topo_x_pos, topo_y_pos] = topo_ar[:, 2]\n",
    "topo_x_min, topo_x_max = topo_x.min(), topo_x.max()\n",
    "topo_y_min, topo_y_max = topo_y.min(), topo_y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b14a65-e58b-4b08-8dc0-f5ee8e47d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_end = 150.\n",
    "h0 = 30.\n",
    "xl = topo_x.max() - topo_x.min()\n",
    "yl = topo_y.max() - topo_y.min()\n",
    "Tsea = 15.\n",
    "Tbot = 600.\n",
    "kappa = 25.\n",
    "air_lapse = 5.\n",
    "\n",
    "# Set number of data points\n",
    "N_0 = 2000\n",
    "N_b_b = 2000\n",
    "N_b_s = 5000\n",
    "N_b = N_b_b + N_b_s\n",
    "N_r = 50000\n",
    "\n",
    "# Set boundary\n",
    "tmin = 0.\n",
    "tmax = t_end\n",
    "zmin = 0.\n",
    "zmax = h0 + topo_ar[:, 2].max() * 6.\n",
    "xmin = 0.\n",
    "xmax = xl\n",
    "ymin = 0.\n",
    "ymax = yl\n",
    "\n",
    "# Lower bounds\n",
    "lb = tf.constant([tmin, xmin, ymin, zmin], dtype=DTYPE)\n",
    "# Upper bounds\n",
    "ub = tf.constant([tmax, xmax, ymax, zmax], dtype=DTYPE)\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e153a554-290c-49f2-8805-c3bec58fd59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "\n",
    "def tf_h_fn_inv(t, x, y, amp0, t_decay):\n",
    "    amp0 = tf.cast(amp0, dtype=DTYPE)\n",
    "    one = tf.ones(1)\n",
    "    amp = tf.where(t < t_decay, amp0, one + (amp0 - one) * (t_end - t)/ (t_end - t_decay))\n",
    "    xy = tf.cast(tf.concat([x, y], axis=1), dtype=DTYPE)\n",
    "    h_interp = tfp.math.batch_interp_regular_nd_grid(\n",
    "        xy, [topo_x_min, topo_y_min,], [topo_x_max, topo_y_max], topo_pivot, axis=-2)\n",
    "    return h0 + amp * tf.reshape(h_interp, tf.shape(x))\n",
    "\n",
    "def tf_h_fn_init(x, y, amp0):\n",
    "    zero = tf.zeros(1)\n",
    "    one = tf.ones(1)\n",
    "    return tf_h_fn_inv(zero, x, y, amp0, one)\n",
    "\n",
    "def T_init(x, y, z, amp0):\n",
    "    return Tbot - T_grad0(x, y, amp0) * z\n",
    "\n",
    "# Define boundary condition\n",
    "def T_surf(surf_z, sealevel_z=h0, lapse=air_lapse):\n",
    "    elevation = surf_z - sealevel_z\n",
    "    return tf.ones(tf.shape(surf_z), dtype=DTYPE) * Tsea - elevation * lapse\n",
    "\n",
    "def T_bot(z):\n",
    "    return tf.constant(Tbot, shape=z.shape, dtype=DTYPE)\n",
    "    \n",
    "# T_grad_inv = lambda t, x, y, amp0: (Tbot - T_surf(tf_h_fn_inv(t, x, y, amp0, t_decay=70.))) / tf_h_fn_inv(t, x, y, amp0, t_decay=70.)\n",
    "T_grad_inv = lambda t, x, y, amp0, t_decay: (Tbot - T_surf(tf_h_fn_inv(t, x, y, amp0, t_decay))) / tf_h_fn_inv(t, x, y, amp0, t_decay)\n",
    "T_grad0 = lambda x, y, amp0: (Tbot - T_surf(tf_h_fn_init(x, y, amp0))) / tf_h_fn_init(x, y, amp0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a47f9a8-965e-4b79-a1a6-cb6f2044c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(amp0, t_decay):    \n",
    "    # Draw uniform sample points for initial boundary data\n",
    "    t_0 = tf.ones((N_0, 1), dtype=DTYPE) * lb[0]\n",
    "    x_0 = tf.random.uniform((N_0, 1), lb[1], ub[1], dtype=DTYPE)\n",
    "    y_0 = tf.random.uniform((N_0, 1), lb[2], ub[2], dtype=DTYPE)\n",
    "    z_0 = tf.random.uniform((N_0, 1), lb[3], tf_h_fn_init(x_0, y_0, amp0), dtype=DTYPE)\n",
    "    X_0 = tf.concat([t_0, x_0, y_0, z_0], axis=1)\n",
    "    # Evaluate intitial condition at z_0\n",
    "    T_0 = T_init(x_0, y_0, z_0, amp0)\n",
    "\n",
    "    # Boundary data\n",
    "    mid_t = lb[0]+(ub[0]-lb[0])*.3 #to separate t space into two and sample each\n",
    "    t_b0 = tf.random.uniform((N_b_b//2, 1), lb[0], mid_t, dtype=DTYPE)\n",
    "    t_b1 = tf.random.uniform((N_b_b//2, 1), mid_t, ub[0], dtype=DTYPE)\n",
    "    t_b = tf.concat([t_b0, t_b1], axis=0)\n",
    "\n",
    "    x_b = tf.random.uniform((N_b_b, 1), lb[1], ub[1], dtype=DTYPE)\n",
    "    y_b = tf.random.uniform((N_b_b, 1), lb[2], ub[2], dtype=DTYPE)\n",
    "    z_b = lb[3] * tf.ones((N_b_b, 1), dtype=DTYPE)\n",
    "    \n",
    "    t_s0 = tf.random.uniform((N_b_s//2, 1), lb[0], mid_t, dtype=DTYPE)\n",
    "    t_s1 = tf.random.uniform((N_b_s//2, 1), mid_t, ub[0], dtype=DTYPE)\n",
    "    t_s = tf.concat([t_s0, t_s1], axis=0)\n",
    "\n",
    "    x_s = tf.random.uniform((N_b_s, 1), lb[1], ub[1], dtype=DTYPE)\n",
    "    y_s = tf.random.uniform((N_b_s, 1), lb[2], ub[2], dtype=DTYPE)\n",
    "    z_s = tf.constant(tf_h_fn_inv(t_s, x_s, y_s, amp0, t_decay), dtype=DTYPE)\n",
    "\n",
    "    t_bs = tf.concat([t_b, t_s], axis=0)\n",
    "    x_bs = tf.concat([x_b, x_s], axis=0)\n",
    "    y_bs = tf.concat([y_b, y_s], axis=0)\n",
    "    z_bs = tf.concat([z_b, z_s], axis=0)\n",
    "    X_bs = tf.concat([t_bs, x_bs, y_bs, z_bs], axis=1)\n",
    "\n",
    "    # Evaluate boundary condition\n",
    "    T_b = T_bot(z_b)\n",
    "    T_s = T_surf(z_s)\n",
    "    T_bs = tf.concat([T_b, T_s], axis=0)\n",
    "\n",
    "    # Collect boundary and inital data in lists\n",
    "    X_data = tf.concat([X_0, X_bs], axis=0)\n",
    "    T_data = tf.concat([T_0, T_bs], axis=0)\n",
    "    \n",
    "    return X_data, T_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1583d-a5d8-4bb2-b369-c49333cd8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINNInv3D(PINN3D):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.u0 = tf.constant(1.)\n",
    "        self.u1 = tf.constant(1.)\n",
    "        self.t1 = tf.constant(25.)\n",
    "        self.t2 = tf.constant(75.)\n",
    "        self.amp0 = tf.constant(3.)\n",
    "        \n",
    "        self.transform = tf.keras.layers.Lambda(\n",
    "            lambda x: x[:, 0:1] * (\n",
    "                self.Tbot - T_grad_inv(x[:, 0:1], x[:, 1:2], x[:, 2:3], self.amp0, self.t2) * x[:, 3:4])   \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f7f2f8-5d81-4dde-939e-31fd6404fa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution\n",
    "from scipy.optimize import shgo\n",
    "from scipy.optimize import direct\n",
    "from scipy.optimize import dual_annealing\n",
    "import os\n",
    "\n",
    "class InvSolver(PINN3DSolver):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.age_loss_hist = []\n",
    "        self.u1_hist = []\n",
    "        self.t1_hist = []\n",
    "        self.amp0_hist = []\n",
    "        self.u0_hist = []\n",
    "        self.t2_hist = [] #t2 is t_decay\n",
    "        self.inv_it_hist = []\n",
    "        self.inv_iter = 0\n",
    "        #the following needs to be set up for optimization\n",
    "        self.data_age = tf.constant([])\n",
    "        self.data_method = []\n",
    "        self.data_radi = []\n",
    "        self.data_err = tf.constant([])\n",
    "        self.data_x = []\n",
    "        self.data_y = []\n",
    "        self.savepath = 'saved_inv_model3d'\n",
    "        \n",
    "    def fun_u(self, t):\n",
    "        return tf_uplift_inv(t, self.model.u0, self.model.u1, self.model.t1)\n",
    "    \n",
    "    def fun_h(self, t, x0, y0, amp0, t_amp0):\n",
    "        return tf_h_fn_inv(t, [[x0]], [[y0]], amp0, t_amp0)[0]\n",
    "\n",
    "    def fun_u_inv(self, t, x):\n",
    "        u0, u1, t1, _, _ = x\n",
    "        return tf_uplift_inv(t, tf.constant(u0, dtype=DTYPE),\n",
    "                             tf.constant(u1, dtype=DTYPE),\n",
    "                             tf.constant(t1, dtype=DTYPE))\n",
    "    \n",
    "    def get_tT(self, x0, y0, x):\n",
    "        u0, u1, t1, t2, amp0 = x\n",
    "        sample_t = tf.linspace(self.model.lb[0], self.model.ub[0], 100)\n",
    "        u = self.fun_u_inv(sample_t, x)\n",
    "        x_ar = tf.ones_like(u) * x0\n",
    "        y_ar = tf.ones_like(u) * y0\n",
    "        dpth = []\n",
    "        for i in range(len(sample_t)):\n",
    "            d = tfp.math.trapz(u[i:], x=sample_t[i:])\n",
    "            dpth.append(d) # this is the depth relative to the present surface\n",
    "\n",
    "        h_paleo = self.fun_h(sample_t, x0, y0, tf.constant(amp0, dtype=DTYPE), tf.constant(t2, dtype=DTYPE)) # paleo surface height\n",
    "        h_present = self.fun_h(sample_t[-1], x0, y0, tf.constant(amp0, dtype=DTYPE), tf.constant(t2, dtype=DTYPE)) # present surface height\n",
    "        depth = tf.stack(dpth) + h_paleo - h_present  # paleo depth\n",
    "        \n",
    "        z = self.fun_h(sample_t, x0, y0, self.model.amp0, self.model.t2) - depth\n",
    "        sample_T = tf.reshape(self.model(tf.stack([sample_t, x_ar, y_ar, z], axis=1)), sample_t.shape)\n",
    "        return sample_t, sample_T\n",
    "            \n",
    "    def age_loss(self, x):\n",
    "        age_pred = []\n",
    "        for hx, hy, hm, hr in zip(self.data_x, self.data_y, self.data_method, self.data_radi):\n",
    "            sample_t, sample_T = self.get_tT(hx, hy, x)\n",
    "            age_pred.append(self.pred_age(sample_t, sample_T, method=hm, grain_radius=hr))\n",
    "            \n",
    "        return tf.reduce_mean(tf.square((age_pred - self.data_age)/self.data_err))\n",
    "\n",
    "    def solve_with_scipy(self, bounds,\n",
    "                         samples=100, disp=True, maxiter=100, maxfun=None,\n",
    "                         optimizer='shgo', sampling_method='simplicial',local_bias=False,\n",
    "                         strategy='best2bin', mutation=(0.5, 1), recombination=0.7,\n",
    "                         popsize=30, eps=1e-3):\n",
    "        self.runpath = os.path.join(self.savepath, self.runname)\n",
    "        if not(os.path.exists(self.runpath)):\n",
    "            os.mkdir(self.runpath)\n",
    "            \n",
    "        def obj_fn(x):\n",
    "            u0, u1, t1, t2, amp0 = x\n",
    "            if t1 >= t2:\n",
    "                return 99999.\n",
    "            else:\n",
    "                age_loss = self.age_loss(x)\n",
    "                self.u0_hist.append(u0)\n",
    "                self.u1_hist.append(u1)\n",
    "                self.t1_hist.append(t1)\n",
    "                self.amp0_hist.append(amp0)\n",
    "                self.t2_hist.append(t2)\n",
    "                self.inv_it_hist.append(self.inv_iter)\n",
    "                self.current_age_loss = age_loss.numpy()\n",
    "                self.age_loss_hist.append(self.current_age_loss)\n",
    "            return age_loss\n",
    "\n",
    "        def save_inv_history(file):\n",
    "            np.savez(file, u0_hist=self.u0_hist, u1_hist=self.u1_hist, amp0_hist=self.amp0_hist,\n",
    "                     t1_hist=self.t1_hist, t2_hist=self.t2_hist,\n",
    "                     inv_it_hist=self.inv_it_hist, age_loss_hist=self.age_loss_hist\n",
    "                     )\n",
    "            \n",
    "        def scipy_callback(*xf):\n",
    "            self.inv_iter += 1\n",
    "            x = xf[0]\n",
    "            fun = obj_fn(x)\n",
    "            runpath = self.get_runpath()\n",
    "            print(('It {:6d} fun {:.4g}: run time = {:.4g} seconds;'\n",
    "                   'u0 = {:.4g} u1 = {:.4g} t1 = {:.4g} t2 = {:.4g} amp0 = {:.4g}').format(\n",
    "                   self.inv_iter, fun, time()-tic, x[0], x[1], x[2], x[3], x[4])\n",
    "                 )\n",
    "            save_inv_history(runpath + '/inv_solver_hist')\n",
    "            self.save_history(runpath + '/solver_hist')\n",
    "            with open(runpath + '/inv_log.txt', 'a') as log_f:\n",
    "                log_f.write(f'it {self.inv_iter} - fun: {fun}; x: {x}\\n')\n",
    "                \n",
    "            return self.current_loss < 1 and self.current_age_loss < .01\n",
    "\n",
    "        tic = time()\n",
    "        runpath = self.get_runpath()\n",
    "        with open(runpath + '/inv_log.txt', 'a') as log_file:\n",
    "            log_file.write(f'-- search begin -- bounds: {bounds}\\n')\n",
    "\n",
    "        if optimizer=='shgo':\n",
    "            res = shgo(obj_fn, bounds, n=samples, options={'maxiter':maxiter, 'disp':disp},\n",
    "                        sampling_method=sampling_method, callback=scipy_callback)\n",
    "        elif optimizer=='DE':\n",
    "            res = differential_evolution(obj_fn, bounds, strategy=strategy, init=sampling_method,\n",
    "                   disp=disp, maxiter=maxiter, popsize=popsize, polish=local_bias,\n",
    "                   mutation=mutation, recombination=recombination, callback=scipy_callback)\n",
    "        elif optimizer=='direct':\n",
    "            res = direct(obj_fn, bounds, maxiter=maxiter, maxfun=maxfun, eps=eps,\n",
    "                          locally_biased=local_bias, callback=scipy_callback)\n",
    "        elif optimizer=='DA':\n",
    "            res = dual_annealing(obj_fn, bounds, maxiter=maxiter, maxfun=maxfun, callback=scipy_callback)\n",
    "        else:\n",
    "            raise Exception('optimizer is not available')\n",
    "\n",
    "        with open(runpath + '/inv_log.txt', 'a') as log_file:\n",
    "            log_file.write(f'-- search ends -- run time: {time() - tic:.0f}; optima: {res.x}\\n')\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0868424c-9e55-40ab-a3b8-596e8b0154a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw uniformly sampled collocation points\n",
    "mid_t = lb[0]+(ub[0]-lb[0])*.3\n",
    "t_r0 = tf.random.uniform((N_r//2, 1), lb[0], mid_t, dtype=DTYPE)\n",
    "t_r1 = tf.random.uniform((N_r//2, 1), mid_t, ub[0], dtype=DTYPE)\n",
    "t_r = tf.concat([t_r0, t_r1], axis=0)\n",
    "# t_r = tf.random.uniform((N_r, 1), lb[0], ub[0], dtype=DTYPE)\n",
    "x_r = tf.random.uniform((N_r, 1), lb[1], ub[1], dtype=DTYPE)\n",
    "y_r = tf.random.uniform((N_r, 1), lb[2], ub[2], dtype=DTYPE)\n",
    "z_r = tf.random.uniform((N_r, 1), lb[3], tf_h_fn_init(x_r, y_r, 1.), dtype=DTYPE)\n",
    "X_r = tf.concat([t_r, x_r, y_r, z_r], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66c986-db80-4a61-8975-7c8e3a2f12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ages(txt, DYTPE='float32'):\n",
    "    ar = np.loadtxt(txt, dtype='str')\n",
    "    x = ar[:, 0].astype(DTYPE)\n",
    "    y = ar[:, 1].astype(DTYPE)\n",
    "    ages = tf.constant(ar[:, 2].astype(DTYPE))\n",
    "    errs = tf.constant(ar[:, 3].astype(DTYPE))\n",
    "    radi = ar[:, 4].astype(DTYPE)\n",
    "    methods = ar[:, 5]\n",
    "    return x, y, ages, errs, radi, methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8802ddae-d594-487e-80ce-072f015c07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_rate(step, initial_rate=1e-3, decay_rate=.9, decay_steps=1000):\n",
    "    return initial_rate * decay_rate ** (step / decay_steps)\n",
    "    \n",
    "# x = np.linspace(0, 500000, 1000)\n",
    "# plt.plot(x,  l_rate(x, decay_steps=10000))\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d479b404-5389-4f16-a85a-453bf3011ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = PINNInv3D(lb, ub, num_hidden_layers=16, num_neurons_per_layer=20)\n",
    "model.build(input_shape=(None, 4))\n",
    "\n",
    "# lr = 1e-3\n",
    "# lr = tf.keras.optimizers.schedules.PiecewiseConstantDecay([20000],[1e-2, 1e-3])\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(1e-3, decay_steps=10000, decay_rate=0.9)\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# Initilize PINN solver\n",
    "solver = InvSolver(model, X_r)\n",
    "solver.savepath = 'saved_inv_model3d'\n",
    "\n",
    "solver.data_x, solver.data_y, solver.data_age, solver.data_err, solver.data_radi, solver.data_method = read_ages('dabie_ages.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5da8b8-e37a-404c-ba56-aaf40649165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink(b0, x, frac=.9):\n",
    "    d = (np.max(b0) - np.min(b0)) * frac * .5\n",
    "    b1l = x - d\n",
    "    b1u = x + d\n",
    "    dl = b1l - np.min(b0)\n",
    "    du = np.max(b0) - b1u\n",
    "    if dl < 0:\n",
    "        b1l -= dl\n",
    "        b1u -= dl\n",
    "    elif du < 0:\n",
    "        b1l += du\n",
    "        b1u += du\n",
    "\n",
    "    return (b1l, b1u) \n",
    "    \n",
    "def new_bounds(bounds, optima, optima_0, frac=.9):\n",
    "    new_bounds = []\n",
    "    for b0, x, op0 in zip(bounds, optima, optima_0):\n",
    "        r = np.diff(b0)[0]\n",
    "        if np.abs((x - op0) / r) < .05:\n",
    "            b1 = shrink(b0, x, frac=frac)\n",
    "        else:\n",
    "            b1 = b0\n",
    "            \n",
    "        new_bounds.append(b1)\n",
    "        \n",
    "    return new_bounds\n",
    "\n",
    "def zoom_in(bounds, optima, optima_0):\n",
    "    new_bounds = []\n",
    "    for b0, x, op0 in zip(bounds, optima, optima_0):\n",
    "        r = np.diff(b0)[0]\n",
    "        if np.abs((x - op0) / r) < .05:\n",
    "            d = np.abs(np.array(b0) - x).min()\n",
    "            b1 = (x - d, x + d)\n",
    "        else:\n",
    "            b1 = b0\n",
    "            \n",
    "        new_bounds.append(b1)\n",
    "\n",
    "    return new_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f4506-2eca-4db3-a19f-f4fc74eb691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_adam_n(adam_n, up_by=1.5, max=10000):\n",
    "    return min(max, np.int32(adam_n * up_by))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e823a1ec-d409-4ca9-884f-843ebd89721d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "# Start timer\n",
    "tic = time()\n",
    "\n",
    "bounds = [(0., 1.), (0., 1.), (0., 50.), (50., 100.), (0., 6.)]\n",
    "ops = [np.mean(a) for a in bounds]\n",
    "solver.model.u0, solver.model.u1, solver.model.t1, solver.model.t2, solver.model.amp0 = tf.constant(ops, dtype=DTYPE)\n",
    "\n",
    "maxiter, maxfun = 30 + 2, 1000\n",
    "runpath = solver.get_runpath()\n",
    "np.save(runpath  + '/inv_X_r', X_r)\n",
    "\n",
    "adam_n = 100\n",
    "for i in range(50):\n",
    "    X_data, T_data = generate_data(solver.model.amp0, solver.model.t2)\n",
    "    solver.solve_with_Adam(optim, X_data, T_data, N=adam_n, echofreq=adam_n, savefreq=-1)\n",
    "    res = solver.solve_with_scipy(bounds, maxiter=maxiter, maxfun=maxfun,\n",
    "                                  optimizer='direct', eps=1e-1, local_bias=False\n",
    "                                  )\n",
    "    tf.saved_model.save(model, os.path.join(runpath, 'model' + str(i)))\n",
    "    bounds = new_bounds(bounds, res.x, ops, frac=.9)\n",
    "    # bounds = zoom_in(bounds, res.x, ops)\n",
    "    ops = res.x\n",
    "    adam_n = new_adam_n(adam_n, up_by=1.2, max=20000)\n",
    "    solver.model.u0, solver.model.u1, solver.model.t1, solver.model.t2, solver.model.amp0 = tf.constant(ops, dtype=DTYPE)\n",
    "\n",
    "# Print computation time\n",
    "print('\\nComputation time: {} seconds'.format(time() - tic));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
